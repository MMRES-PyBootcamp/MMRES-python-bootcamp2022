{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp2021/blob/master/04_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2 - Pandas (First part) TODO\n",
    "> An introduction on Pandas basics. TODO Here you will hear (just a bit) about Python *packages* and *modules*. Then you will be introduced to *lists* and *dictionaries*, some of the most versatile data types in Python. Finally, you will become familiar with the concept of *flow control* and the definition of your own *functions*. TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline TODO\n",
    " * [Importing packages](#Importing-packages)\n",
    " * [Lists](#Lists)\n",
    " * [Strings as sequential data types](#Strings-as-sequential-data-types)\n",
    " * [Dictionaries](#Dictionaries)\n",
    " * [Flow control](#Flow-control)\n",
    "   * [The `for` loop](#The-for-loop)\n",
    "   * [The `if`, `elif` and `else` clauses](#The-if,-elif-and-else-clauses)\n",
    " * [User defined functions](#User-defined-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b> Practice cells announce exercises that you should try during the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Extension:</b> Extension cells correspond to exercises (or links to contents) that are a bit more advanced. We recommend to try them after the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> Tip cells just give some advice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b> Caveat cells warn you about the most common pitfalls one founds when starts his/her path learning Python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This document is devised as a tool to enable your self-learning process. If you get stuck at some step or need any kind of help, please don't hesitate to raise your hand and ask for the teacher's guidance.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jd6Y3hlZwe_y",
    "tags": []
   },
   "source": [
    "## What is Pandas?\n",
    "\n",
    "When dealing with numeric matrices and vectors in Python, [NumPy](https://numpy.org/) makes life a lot easier. However, those used to work with dedicated languages like [R](https://www.r-project.org/), doing data analysis directly with NumPy feels like a step back. Fortunately, some nice folks have written the Python Data Analysis Library (a.k.a. [Pandas](http://pandas.pydata.org/)). Pandas provides an R-like DataFrame, produces high quality plots with [matplotlib](https://matplotlib.org/), and integrates nicely with other libraries that expect NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series and DataFrames\n",
    "\n",
    "Pandas works with `Series` of data, that then are arranged in `DataFrame` objects. A dataframe is the object closest to an Excel spreadsheet that we will see throughout the boot camp. Dataframes, though, given that they are integrated in Python and can be combined with so many different packages, are much more powerful than simple Excel spreadsheets. We use to load Pandas with the `pd` alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load package with its corresponding alias\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data as a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load data with Pandas we use functions like [`pd.read_excel()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) and [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). As you may have guessed, we choose depending on the format of our input data. For example, `pd.read_excel()` works with `xlsx`, `xls`... `pd.read_csv()` with `csv`, `tsv`, `txt`...\n",
    "\n",
    "These functions have multiple arguments providing great flexibility when importing data, like skipping some rows/columns, specifying the column delimiter or picking a particular sheet within a spreadsheet. Let's begin by importing [`ToySpreadsheet.xlsx`](MMRES-python-bootcamp2022/datasets/ToySpreadsheet.xlsx) from `/MMRES-python-bootcamp2022/datasets` sub-folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading an Excel SpreadSheet and storing it in as a DataFrame called `df`\n",
    "df = pd.read_excel(io='datasets/ToySpreadsheet.xlsx')\n",
    "\n",
    "# Return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data type of `df`\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataframe basic inspection\n",
    "\n",
    "Usually, the first thing one should do with a new DataFrame is getting familiar with the its data. Pandas DataFrame objects have many *methods* to this aim, like [`.head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html), [`.tail()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html), [`.describe()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame tail\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame (basic) statistical description for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`.info()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) method is particularly useful. It gives the names *columns*, the data type stored in each column and the memory devoted to store the DataFrame. It also shows the number of non-null values by column, from which we can easily estimate the number of *missing values* (`NaN`) by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame general information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these methods, Pandas DataFrame objects very useful have *attributes* like [`.shape`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html), [`.columns`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html) and \n",
    "[`.index`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.index.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame shape. Remember: (Rows, Columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame rows\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b>\n",
    "\n",
    "Like *methods*, *attributes* are invoked with the dot `.` symbol. In general, *methods* are invoked with a parenthesis (like `.info()`) and *attributes* without them (like `.shape`). Intuitively, you can consider the *attributes* of a Python object as <ins>things it has</ins>, and *methods* as <ins>things it does</ins>. For example, we could imagine a Python object called `cat` with some attributes and methods.\n",
    "+ Atributes: `cat.age`, `cat.weight`, `cat.gender`, `cat.personality`, `cat.eye_color`, `cat.coat_pattern`, ...\n",
    "+ Methods: `cat.purr()`, `cat.meow()`, `cat.chirp()`, `cat.eat()`, `cat.sleep()`, `cat.scratch()`, ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame visual inspection\n",
    "\n",
    "After a basic DataFrame inspection, we can start with a visual exploration. To this aim we can levergae the Pandas DataFrame method [`.plot`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html) and its related \"submethods\" [`.line()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.line.html), [`.bar()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html), [`.barh()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.barh.html), [`.hist()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.hist.html), [`.box()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.box.html), [`.density()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.density.html), [`.area()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.area.html), [`.pie()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.pie.html), [`.scatter()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html), [`.hexbin()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.hexbin.html), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame line plot\n",
    "df.plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b>\n",
    "\n",
    "1) In the 1st code cell below, get a box plot for the DataFrame `df`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a box plot for `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a box plot for `df`\n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b>\n",
    "\n",
    "1) In the 1st code cell below, get a scatter plot for the DataFrame `df`. What happened?\n",
    "2) Try again buy this time declaring `x=` and `y=` parameters for the `.scatter()` method.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "ejercicio"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a scatter plot for `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "ejercicio",
     "solucion"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate a scatter plot for `df`\n",
    "df.plot.scatter(x='Intensity', y='Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame access\n",
    "\n",
    "We can get the information stored in a DataFrame by multiple ways, here we will present the accession by brackets `[]` syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing whole columns\n",
    "\n",
    "In order to access rows, we need to use the brackets syntax: `df[]`. Passing a list of column names inside the brackets grants you access to such columns. Note that there are two pairs of brackets, one enclosing the list of column names (innermost) and one given access to DataFrame columns (outermost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame columns\n",
    "df[['Raw', 'Intensity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing whole rows\n",
    "\n",
    "In order to access rows, we need to use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) followed by the brackets syntax: `df.loc[]`. Passing a list of row indexes inside the brackets grants you access to such rows. Again, note that there are two pairs of brackets, one enclosing the list of row indexes (innermost) and one given access to DataFrame rows (outermost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame rows\n",
    "df.loc[[4, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing columns and rows simultaneously\n",
    "\n",
    "If we want to access the intersection of some columns and rows, we use [`.loc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) followed by the brackets syntax with a comma inside: `df.loc[ , ]`. The list with the rows we wants goes to the left of the comma and the list with the columns to the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing multiple DataFrame rows and columns simultaneously\n",
    "df.loc[[4, 1],  ['Raw', 'Intensity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, you can first put your lists into a variables before accessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing DataFrame columns specifying first the list of indices and columns we want\n",
    "rows = [4, 1]\n",
    "cols = ['Raw', 'Intensity']\n",
    "df.loc[rows, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qECGYMhFwe_0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('Pandas:', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dRXlNyzwe_1"
   },
   "outputs": [],
   "source": [
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dW0u1aYnwe_1"
   },
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKZxbs6swe_2"
   },
   "source": [
    "Notice that the series is indexed by default by integers. We can change this indexing by using a dictionary instead of a list to create the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfQllZnnwe_2"
   },
   "outputs": [],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMoMhXjdwe_3"
   },
   "source": [
    "On the other hand, dataframes can be built from two-dimensional arrays, with the ability of labelling columns and indexing the rows. **Every column in a dataframe is a series**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH2espiFwe_3"
   },
   "outputs": [],
   "source": [
    "# Sampling a 1000 rows 6 cols 2D array from the standard normal distribution and creating DataFrame\n",
    "u = pd.DataFrame(np.random.randn(1000, 6),\n",
    "                 index=np.arange(0, 3000, 3),\n",
    "                 columns=['A', 'B', 'C', 'D', 'E', 'F'])\n",
    "\n",
    "print(type(u))\n",
    "\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOr-n8Lbwe_4"
   },
   "source": [
    "As you might have noticed, it is not the best to look at massive dataframes. There are some functions that allow us to have a nicer look at parts of the dataframe to have an idea of \"how things are going\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QszUh5dVwe_4"
   },
   "outputs": [],
   "source": [
    "u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSgZlKyzwe_5"
   },
   "outputs": [],
   "source": [
    "u.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLfIvV_Awe_5"
   },
   "outputs": [],
   "source": [
    "u.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-peS5fHwe_5"
   },
   "outputs": [],
   "source": [
    "u.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkB-VPofwe_6"
   },
   "source": [
    "### Indexing/Slicing in Pandas\n",
    "\n",
    "The easiest way to access information in a Pandas dataframe, equivalent to the way used in NumPy, is using the `iloc` command. With `iloc` we can use the same indexing techniques that we saw with NumPy in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f__CcBkTwe_6"
   },
   "outputs": [],
   "source": [
    "# Slice-in rows index 125 to 132 (132 included!) from columns index 0, 2 and 5\n",
    "u.iloc[125:132, [0, 2, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYOudgEGwe_6"
   },
   "source": [
    "We can choose specific columns according to their names using `loc` instead of `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE_agQpXwe_6"
   },
   "outputs": [],
   "source": [
    "# Slice-in rows 375 to 393 (393 included!) from columns A, C and F\n",
    "u.loc[375:393, ['A', 'C', 'F']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkotgoA8we_6"
   },
   "source": [
    "However, there are a few different ways of accessing the data in a Pandas dataframe, that typically have a more \"direct\" connection with the actual content fo the dataframe. Individual or sets of columns can also be accessed by their column names. Choosing one single column will give a Series, while two or more will produce a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJ4tGTPFwe_7"
   },
   "outputs": [],
   "source": [
    "u['A'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HID7Eb0dwe_7"
   },
   "outputs": [],
   "source": [
    "u[['A', 'D']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCECWud4we_7"
   },
   "source": [
    "Not only that, we can access a single column without the need of brackets []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlcbT8xPwe_7"
   },
   "outputs": [],
   "source": [
    "u.A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hotY3ZvIwe_7"
   },
   "source": [
    "Or, we can retrieve the elements that satisfy some condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTUZE2nzwe_8"
   },
   "outputs": [],
   "source": [
    "u[u.D > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znDPNtk-we_8"
   },
   "source": [
    "Dataframes provide the `query` functionality for the same purpose. While it is less powerful than boolean indexing, it is often faster and shorter (when names are longer than just `u`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfHCORHbwe_8"
   },
   "outputs": [],
   "source": [
    "u.query('D > 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVuI3r-Twe_8"
   },
   "source": [
    "### Reshaping `DataFrame`\n",
    "\n",
    "We can reshape and concatenate dataframes in a pretty similar way to numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9Srkvq5we_8"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "\n",
    "df1['sample'] = ['A', 'A', 'A', 'B', 'B', 'B']\n",
    "df1['replicate'] = ['01', '02', '03', '01', '02', '03']\n",
    "df1['protein'] = 'P02768'\n",
    "df1['value1'] = np.random.randn(6)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Rh2bHncwe_8"
   },
   "outputs": [],
   "source": [
    "pivot_df1 = df1.pivot(index='replicate', columns='sample', values='value1')\n",
    "\n",
    "pivot_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UDugR2Twe_9"
   },
   "source": [
    "### Computing With `DataFrames`\n",
    "\n",
    "We can calculate with `DataFrames` or their columns (which are `Series`) the same way we would work with numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kr4LjYXqwe_9"
   },
   "outputs": [],
   "source": [
    "df1['value2'] = 1 / df1['value1']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kz_Oravuwe_9"
   },
   "outputs": [],
   "source": [
    "np.mean(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-4MfgiPwe_9"
   },
   "source": [
    "We can also apply functions to the whole dataset or specific columns with the `apply` command. `apply` acts on the whole column at a time (i.e. a Pandas `Series`), so we can compute things that depend on several values of the column, for instance, the mean value. To apply functions in a real element-by-element basis the function `applymap` or `Series.apply` should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AX8bRzhDwe_9"
   },
   "outputs": [],
   "source": [
    "def mean(col):\n",
    "    return sum(col) / len(col)\n",
    "\n",
    "df1[['value1', 'value2']].apply(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UA0KJsYqwe_9"
   },
   "source": [
    "While most can be directly calculated (including the given example of the mean), `apply` also works on columns with strings or categorical data, where no mathematical operations are defined. The limit is the imagination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5ONVli7we_9"
   },
   "source": [
    "### Combining `DataFrames`\n",
    "\n",
    "Something we will do quite often as scientists is combining data from different sources into one single source. This can be achieved by different commands in Pandas, depending on the actual goal we want.\n",
    "\n",
    "To begin with, appending new rows of data is achieved by the command `append`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWuaqmG6we_-"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "\n",
    "df2['sample'] = ['A', 'A', 'A', 'B', 'B', 'B']\n",
    "df2['replicate'] = ['01', '02', '03', '01', '02', '03']\n",
    "df2['protein'] = 'P69892'\n",
    "df2['value1'] = np.random.randn(6)\n",
    "df2['value2'] = 1 / df2['value1']\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrVuQ26xwe_-"
   },
   "outputs": [],
   "source": [
    "df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te0sJ4xYwe_-"
   },
   "source": [
    "The same result can be obtained with `concat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whMeHgI1we_-"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5WZ6nRVwe_-"
   },
   "source": [
    "### Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ji6npHcMwe_-"
   },
   "outputs": [],
   "source": [
    "df.groupby('protein').agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4gLCDWYwe_-"
   },
   "outputs": [],
   "source": [
    "df.groupby(['protein', 'sample']).agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-5yICjnwe_-"
   },
   "outputs": [],
   "source": [
    "df.groupby(['protein', 'sample', 'replicate']).agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-s3-1l8Lwe__"
   },
   "outputs": [],
   "source": [
    "df.groupby('protein').transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKHk3OU7we__"
   },
   "outputs": [],
   "source": [
    "df.groupby('protein')['value1', 'value2'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRQpvJOIwe__"
   },
   "outputs": [],
   "source": [
    "for g, g_df in df.groupby(['protein', 'sample']):\n",
    "    print(g_df)\n",
    "    print(f\"{g} --> mean value1: {np.mean(g_df['value1'])}\")\n",
    "    print(f\"      mean value2: {np.mean(g_df['value2'])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zh5TW5Ewe__"
   },
   "outputs": [],
   "source": [
    "df.groupby(['protein', 'sample']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZymA9jdswe__"
   },
   "outputs": [],
   "source": [
    "df.pivot_table(index='protein',\n",
    "               columns='sample', \n",
    "               aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-V5VY3mGwfAA"
   },
   "outputs": [],
   "source": [
    "df.pivot_table(index='protein',\n",
    "               columns='sample',\n",
    "               aggfunc={'value1': min,\n",
    "                        'value2': max})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBie1CnhwfAA"
   },
   "source": [
    "### Loading and saving dataframes\n",
    "\n",
    "To load and save Pandas dataframes we will use the `to_csv` and `read_csv` commands. Whenever the dataframe does not contain any kind of column that is of type `object` we can also use feather format with `to_feather`. In case we have objects in the cells, such as functions, for example, we can use pickle format with `to_pickle`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6tARwXFwfAA"
   },
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')\n",
    "pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiGpBxl3wfAA"
   },
   "source": [
    "But, as an addition, Pandas has special commands to load and save Excel spreadsheets (yay!). However, to use it you'll need the `openpyxl` and `xlrd` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGdlb3UvwfAA"
   },
   "outputs": [],
   "source": [
    "df.to_excel('test.xlsx', sheet_name='My sheet')\n",
    "pd.read_excel('test.xlsx', 'My sheet', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Q3OWleewfAA"
   },
   "source": [
    "**Exercise 5**: Download [this dataset](https://raw.githubusercontent.com/ChihChengLiang/pokemongor/master/data-raw/pokemons.csv) and load it, using the first column as the index. Take a look at it, and do the following things:\n",
    "- Choose the columns 'Identifier', 'BaseStamina', 'BaseAttack', 'BaseDefense', 'Type1' and 'Type2' \n",
    "- Create a function that lowercases strings and apply it to 'Type1' and 'Type2' (*Extra: just capitalize the strings, i.e., leave the first letter uppercase and lowercase the rest*)\n",
    "- Create a function that returns a Boolean value (don't be afraif by this, it is a function that returns either True or False) that tells if a Pokémon has high stamina (BaseStamina>170) or not. Store this information in a new column and show the list of Pokémon with high stamina\n",
    "- Show the instructor the last 15 rows of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUPGHqP2wfAA"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ChihChengLiang/pokemongor/master/data-raw/pokemons.csv', \n",
    "                 index_col=0)\n",
    "\n",
    "df = df[['Identifier', 'BaseStamina', 'BaseAttack', 'BaseDefense', 'Type1', 'Type2']]\n",
    "\n",
    "capitalize = lambda st: st.capitalize()\n",
    "\n",
    "for col in ['Type1', 'Type2']:\n",
    "    df[col] = df[col].apply(capitalize)\n",
    "    \n",
    "def highstamina(x):\n",
    "    return True if x > 170 else False\n",
    "\n",
    "df['HighStamina'] = df.BaseStamina.apply(highstamina)\n",
    "\n",
    "print(df[df['HighStamina'] == True].Identifier)\n",
    "\n",
    "df.tail(15)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "04_Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
