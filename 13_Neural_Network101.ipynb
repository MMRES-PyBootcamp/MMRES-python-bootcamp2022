{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d487747-246d-43d3-954a-0c08fdae2d05",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp2022/blob/main/13_Neural_Network101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b3698-f2fb-4c06-ac9d-ffcf43d01d97",
   "metadata": {},
   "source": [
    "# Part I: Fully conected Neural Networks\n",
    "In the introduction we got to know the basic fully-connected neural network architecture.  \n",
    "We will revisit it later in our session about backpropagation more detail.  \n",
    "Here, we first look at how to implement such a neural network in `torch` (or PyTorch),  \n",
    "one of the leading automatic differentiation platforms for machine learning and AI.\n",
    "\n",
    "Contemporary alternatives are [JAX](https://jax.readthedocs.io/en/latest/) and [TensorFlow](https://www.tensorflow.org/),  \n",
    "which are backed by google and both have their advantages and disadvantages. All libraries are able to perform the tasks  \n",
    "we are looking at, and it is solely a matter of preference which one we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e297d74b-28cb-4403-82c3-70917fbf7855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qottmann/anaconda3/envs/test/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bd1c9a-2dc5-4d67-93b8-54f198760414",
   "metadata": {},
   "source": [
    "To build a neural network in (py)torch, you are expected to fill a \"template\" class  \n",
    "that has a `__init__` and `forward` method. This varies for different machine learning  \n",
    "frameworks, but the overall logic is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57c9db8d-b0ee-4d3e-b5a6-124b85c41d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 28*28\n",
    "out_dim = 10\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.neural_network = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),  # input dimension, hidden1 dimension\n",
    "            nn.ReLU(),               # Non-linear activation function\n",
    "            nn.Linear(512, 512),     # hidden1 dimension, hidden2 dimension\n",
    "            nn.ReLU(),               # Non-linear activation function\n",
    "            nn.Linear(512, out_dim), # hidden2 dimension, output dimension\n",
    "            #nn.Softmax(dim=1)        # special output activation function\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)          # input data preparation\n",
    "        output = self.neural_network(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abe9e013-74ff-4b10-b2be-fd03becbc7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (neural_network): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab69d8-01f7-41af-910a-6fc955a0f65d",
   "metadata": {},
   "source": [
    "For parallelization, PyTorch (and other ML frameworks) are built to process data in batches.  \n",
    "Therefore, the input is always assumed to have the first dimension to be the `batch_size`.  \n",
    "If we want to process a single input, we need to accont for a dummy dimension `batch_size=1`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96a0a90f-2061-47a7-8c73-0d2819e5bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X = torch.rand(in_dim)\n",
    "    output = model(X) # results in an error\n",
    "except:\n",
    "    X = torch.rand(1, in_dim)\n",
    "    output = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd46f0ad-d3ed-46d2-9d2b-a0493069f1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b4ae2-44d3-4d74-bbea-951715d745c4",
   "metadata": {},
   "source": [
    "E1: Due to the `flatten` function in the forward pass, the input is rather flexible, try inputting alternatively shaped tensors. What is the constraint that needs to be fulfilled?    \n",
    "Here is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08ea8826-5566-405f-be65-be7d483b9884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0053, -0.0237,  0.0093, -0.0687,  0.0061,  0.0333, -0.0068, -0.0198,\n",
       "          0.0557,  0.0745]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(1, 2, 14, 28)\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd149842-c9d8-404a-a9cf-165197674ae8",
   "metadata": {},
   "source": [
    "E2: We want the output of our NN to be the probability distribution for `out_dim = 7` different categories.  \n",
    "Modify the network such that the output resembles a proper probability distribution, i.e. that \n",
    "$$\\sum_{i=1}^\\text{out_dim} p_i = 1$$ \n",
    "and $1\\geq p_i \\geq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a39c0ea4-215f-434a-81d9-08687acfb72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(torch.sum(model(X)), torch.tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27bb0f62-bd08-4b92-92c4-aa59431b67ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(model(X)>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3c46b-641e-4622-a41b-4595040e6613",
   "metadata": {},
   "source": [
    "(Note that you can use most of the standard `numpy` functions in torch)  \n",
    "Hint: Look up the so-called softmax function $\\text{Softmax}: \\mathbb{R}^m \\mapsto \\mathbb{R}^m$\n",
    "$$\n",
    "\\left(\\text{Softmax}(x)\\right)_i = \\frac{e^{x_i}}{\\sum_{j=1}^m e^{x_j}}\n",
    "$$\n",
    "for $x \\in \\mathbb{R}^m$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d52c2-46a3-4a0d-96ef-f2ebd9eb7ece",
   "metadata": {},
   "source": [
    "# Part II: Backpropagation\n",
    "We understand the _forward pass_ of a neural network, now it is time to learn how to optimize it. Curiosly, this is done in a similar fashion but in the reverse direction through a _backward pass_ via an algorithm called backpropagation. One of the big benefits of modern machine learning libraries like `torch` is they automatically perform this task for us. Still, we should know what is going on under the hood for a deeper understanding.\n",
    "\n",
    "\n",
    "For this, we introduce the vector form of the forward pass in terms of the activation\n",
    "$$a^\\ell = f(z^\\ell)$$\n",
    "with weighted inputs\n",
    "$$z^\\ell = w^\\ell a^{\\ell-1} + b^\\ell.$$\n",
    "Note that all quantities are vectors, except for $w^\\ell$, which is a matrix.  \n",
    "The function $f$ may be different for each layer, though for simplicity we do not specify this explicitly.  \n",
    "The over output of the network is given by\n",
    "$$a^L = f(z^L) = f(w^L f(z^{L-1}) + b^L) =..,$$\n",
    "a nested function of multiple activations and matrix multiplications.\n",
    "\n",
    "One of many possible choices for a loss function is the $\\ell^2$ norm\n",
    "$$C = \\frac{1}{2n} \\sum_x ||y(x) - a^L(x)||^2.$$\n",
    "Here, $a^L$ is the activation of the last layer, i.e. the NN output, and $y(x)$ is the label of the example $x$.  \n",
    "For example, for binary classification (2 classes), $y(x)=(1,0)$ or $y(x)=(0,1)$, depending which class the example belongs to.\n",
    "\n",
    "Our goal is it to minimize this loss function to achieve faithful predictions. This is done via so-called gradient descent.  \n",
    "The idea is to change the trainable parameters of the neural network, $w$ and $b$, in the direction of steepest descent, which is exactly the gradient.  \n",
    "We update the parameters according to\n",
    "$$b^\\ell \\mapsto b^\\ell - \\alpha \\nabla_{b^\\ell} C$$\n",
    "$$w^\\ell \\mapsto b^\\ell - \\alpha \\nabla_{w^\\ell} C$$\n",
    "where $\\alpha$ is a so-called hyper parameter, the learning rate, set by the user. This update rule is repeated many times until a minimum is reached.  \n",
    "In practice we use more involved optimization routines that take  \n",
    "the trajectory of past updates\n",
    "\n",
    "We follow the derivation of the gradient of $C$ based on [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap2.html) and find the equations for backpropagation:\n",
    "\n",
    "$$\\delta^L = \\nabla_aC \\odot f'(z^L)$$\n",
    "$$\\delta^\\ell = \\left((w^{\\ell + 1})^T \\delta^{\\ell+1} \\right) \\odot f'(z^\\ell)$$\n",
    "$$\\frac{\\partial C}{\\partial b^\\ell_j} = \\delta^\\ell_j $$\n",
    "$$\\frac{\\partial C}{\\partial w^\\ell_{jk}} = a^{\\ell-1}_k \\delta^\\ell_j$$\n",
    "\n",
    "Where in the case of the $\\ell^2$ norm above, $\\nabla_a C = \\frac{1}{n} \\sum_x \\sum_i (y_i(x) - a_i(x))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9b807-9047-4e53-a071-0ac92cce9427",
   "metadata": {},
   "source": [
    "Ex: For a forward pass with $x=(1,0)$,\n",
    "$w^1 = \\begin{pmatrix}\n",
    "1 & 2 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 2 \n",
    "\\end{pmatrix}$, $w^2 = \\begin{pmatrix}\n",
    "-1 & -1 & -1\\\\\n",
    "2 & 2 & 2\n",
    "\\end{pmatrix}$, $y=(1,0)$, and $f(x)=|x|$ (element-wise), compute $\\frac{\\partial}{\\partial w^1_{1,1}} C$ and $\\frac{\\partial}{\\partial w^1_{1,2}} C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5602bc6a-869f-4f5e-a8d8-a7f85ccc1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "905341c1-8754-4ffe-b8e0-3a8fe33711f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [batch_size, color_channel, height, width]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [batch_size, color_channel, height, width]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2a6b3aa-1f12-4cc1-9166-bf662004bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# technically you should not do the following because it defeats the purpose of having the data loader in the first place\n",
    "test_data = list(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54f6ee7b-3e61-4884-9a54-a527dd1da532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(ncols=10, figsize=(15, 4))\n",
    "for i, pick in enumerate(np.random.randint(len(test_data),size=10)):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(test_data[pick][0][0][0, :, :])\n",
    "    ax.set_title(f\"label: {test_data[pick][1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7dc4df68-8be9-4c8a-bf46-53332aa00905",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() # nn.MSELoss() # mean squared error (MSE) loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # stochastic gradient descent (SGD) optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ceab6ae-e524-4203-b9e4-01fa1ac963bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 2 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            #print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    # compute accuracy\n",
    "    train_acc = correct/size * 100\n",
    "    return loss, train_acc\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    test_acc = 100*correct\n",
    "    print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    return test_loss, test_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "272a0ee2-08f4-486d-9319-09aecdfb1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Test Error: Accuracy: 78.0%, Avg loss: 1.253924\n",
      "Epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [77], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m train(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m----> 7\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m test(test_dataloader, model, loss_fn)\n\u001b[1;32m      8\u001b[0m train_losss\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m      9\u001b[0m train_accs\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[0;32mIn [76], line 32\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m     30\u001b[0m test_loss, correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     33\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m         pred \u001b[38;5;241m=\u001b[39m model(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.8/site-packages/torchvision/datasets/mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_losss, train_accs = [], []\n",
    "test_losss, test_accs = [], []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\")\n",
    "    train_loss, train_acc = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss, test_acc = test(test_dataloader, model, loss_fn)\n",
    "    train_losss.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_losss.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c349d-1c58-4672-883c-07c635f7ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(10,5), ncols=2)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(train_losss, label=\"train\")\n",
    "ax.plot(test_losss, \"x-\", label=\"test\")\n",
    "\n",
    "ax.set_title(\"loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.legend()\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(train_accs, label=\"train\")\n",
    "ax.plot(test_accs, \"x-\", label=\"test\")\n",
    "\n",
    "ax.set_title(\"accuracy\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9a49454-996d-4c78-9b86-159692e5ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa969134-6741-41e5-aecb-56e0536b366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.297947  [    0/60000]\n",
      "loss: 2.299465  [ 6400/60000]\n",
      "loss: 2.292983  [12800/60000]\n",
      "loss: 2.284586  [19200/60000]\n",
      "loss: 2.278223  [25600/60000]\n",
      "loss: 2.280162  [32000/60000]\n",
      "loss: 2.269141  [38400/60000]\n",
      "loss: 2.281395  [44800/60000]\n",
      "loss: 2.260871  [51200/60000]\n",
      "loss: 2.252883  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 2.253733 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.250625  [    0/60000]\n",
      "loss: 2.248637  [ 6400/60000]\n",
      "loss: 2.250579  [12800/60000]\n",
      "loss: 2.222542  [19200/60000]\n",
      "loss: 2.227488  [25600/60000]\n",
      "loss: 2.230035  [32000/60000]\n",
      "loss: 2.206382  [38400/60000]\n",
      "loss: 2.232095  [44800/60000]\n",
      "loss: 2.197662  [51200/60000]\n",
      "loss: 2.182797  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.185726 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.181756  [    0/60000]\n",
      "loss: 2.173243  [ 6400/60000]\n",
      "loss: 2.185223  [12800/60000]\n",
      "loss: 2.129055  [19200/60000]\n",
      "loss: 2.144519  [25600/60000]\n",
      "loss: 2.147302  [32000/60000]\n",
      "loss: 2.105036  [38400/60000]\n",
      "loss: 2.145507  [44800/60000]\n",
      "loss: 2.090215  [51200/60000]\n",
      "loss: 2.066619  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 2.068863 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.064162  [    0/60000]\n",
      "loss: 2.042694  [ 6400/60000]\n",
      "loss: 2.071392  [12800/60000]\n",
      "loss: 1.970564  [19200/60000]\n",
      "loss: 1.996390  [25600/60000]\n",
      "loss: 1.999000  [32000/60000]\n",
      "loss: 1.933044  [38400/60000]\n",
      "loss: 1.993855  [44800/60000]\n",
      "loss: 1.905854  [51200/60000]\n",
      "loss: 1.869275  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.867323 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.865751  [    0/60000]\n",
      "loss: 1.821033  [ 6400/60000]\n",
      "loss: 1.871470  [12800/60000]\n",
      "loss: 1.716543  [19200/60000]\n",
      "loss: 1.745756  [25600/60000]\n",
      "loss: 1.748014  [32000/60000]\n",
      "loss: 1.667297  [38400/60000]\n",
      "loss: 1.755284  [44800/60000]\n",
      "loss: 1.628358  [51200/60000]\n",
      "loss: 1.583950  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.572019 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcfdbe-e489-4a12-a860-1086b67135ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
